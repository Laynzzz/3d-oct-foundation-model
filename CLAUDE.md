# OCT Foundation Model - Project Status & Configuration

## Project Overview
3D Retinal OCT Foundation Model using Video Joint-Embedding Predictive Architecture (V-JEPA2) for self-supervised learning on retinal OCT volumes.

## ‚úÖ **PRODUCTION READY - TRAINING COMPLETE**

The complete V-JEPA2 3D OCT foundation model is **fully operational** with successful pretraining completed. Three trained checkpoints are available for downstream fine-tuning.

### üéØ **Current Phase: Fine-Tuning Setup**

**Pretraining Status**: ‚úÖ **COMPLETE**
- Three V-JEPA2 checkpoints successfully trained and saved locally
- Ready for downstream classification tasks

**Next Steps**: Setting up fine-tuning pipeline for 4-class diabetes classification

### üö® **CRITICAL REMINDER: Code Update Workflow**
```bash
# Every time you change local files:
git add . && git commit -m "message" && git push
gcloud compute tpus tpu-vm ssh oct-jepa2-v4-32 --zone=us-central2-b --project=d-oct-foundational-model --worker=all --command="cd ~/3d-oct-foundation-model && git pull"
```

### Current Implementation Status

**Pretraining Components Complete:**
- ‚úÖ **Data Pipeline**: GCS DICOM streaming with robust validation
- ‚úÖ **V-JEPA2 Model**: 29.4M parameter 3D ViT with EMA target encoder  
- ‚úÖ **Training Infrastructure**: XLA distributed training on 16 TPU cores
- ‚úÖ **Monitoring**: W&B integration with metrics and checkpointing
- ‚úÖ **Error Handling**: Robust DICOM validation and empty batch handling
- ‚úÖ **Trained Checkpoints**: 3 foundation models ready for fine-tuning

**Fine-Tuning Components (Implementation Complete):**
- ‚úÖ **Classification Pipeline**: Complete diabetes status classification framework  
- ‚úÖ **B2 Data Integration**: Full Backblaze B2 storage integration with caching
- ‚úÖ **Multi-Checkpoint Evaluation**: Ready to compare all 3 pretrained models
- ‚úÖ **Core Infrastructure**: Data pipeline, models, and training components built

## Environment Configuration

### TPU VM Details
- **Instance**: `oct-jepa2-v4-32` (zone: `us-central2-b`)
- **Python Environment**: `/home/layne/miniconda/envs/torch-xla/bin/python`
- **Cores**: 16 TPU v4 cores (4 workers √ó 4 cores each)
- **PyTorch Version**: 2.7.1
- **XLA Version**: 2.7.0

### Data Configuration

**Pretraining Data (GCS):**
- **Bucket**: `gs://layne-tpu-code-sync/OCTdata/OCTdata`
- **Manifest**: `gs://layne-tpu-code-sync/OCTdata/OCTdata/manifest.tsv`
- **Remote Checkpoints**: `gs://layne-tpu-code-sync/checkpoints/vjepa2/`
- **Data Structure**: Individual DICOM files at structured paths

**Local Trained Checkpoints:**
- **Directory**: `/Users/layne/Mac/Acdamic/UCInspire/checkpoints/`
- **Multi-domain**: `best_checkpoint_multi_domain.pt` (1.5GB)
- **Single-domain 01**: `best_checkpoint_single_domain_01.pt` (1.5GB)
- **Single-domain 02**: `best_checkpoint_single_domain_02.pt` (1.5GB)

**Fine-Tuning Data (Backblaze B2):**
- **Endpoint**: `s3.us-west-004.backblazeb2.com`
- **Bucket**: `eye-dataset`
- **Labels**: `/fine-tuneing-data/participants.tsv` (4-class diabetes classification)
- **Participants**: 1001-1100+ with train/val/test splits

### Environment Variables
```bash
export PATH=/home/layne/miniconda/envs/torch-xla/bin:$PATH  # ALWAYS set this
export TF_CPP_MIN_LOG_LEVEL=1
export PJRT_DEVICE=TPU
export DATA_CACHE_DIR=/tmp/oct_cache  # Optional local caching

# Optional: Deprecated XLA_USE_BF16 (use config use_bf16 instead)
export XLA_USE_BF16=1
```

### W&B Configuration
- **Project**: `3d-oct-foundation-model`
- **Entity**: `laynzzz-university-at-buffalo`
- **Artifacts**: Checkpoint saving enabled

## Training Configuration

### Dataset
- **Available data**: 601 OCT volumes from participants 1001-1100
- **Devices**: heidelberg_spectralis, topcon_triton, topcon_maestro2, zeiss_cirrus
- **Data loading**: Single-threaded (`workers: 0`) for stability
- **Validation**: Enhanced DICOM pixel data checking

### Model Parameters
- **Architecture**: V-JEPA2 3D ViT
- **Parameters**: 29.4M
- **Embed dim**: 768, depth: 12
- **Patch size**: [4, 16, 16]
- **Target spacing**: [0.05, 0.02, 0.02] mm (dz, dy, dx)
- **Image size**: [64, 384, 384] (D, H, W)
- **Mask ratio**: 0.6

### Training Parameters
**Production Training:**
- **Global batch size**: 128
- **Per-core batch size**: 2  
- **Gradient accumulation**: 4 steps
- **Learning rate**: 1.5e-3
- **Weight decay**: 0.05
- **Epochs**: 120 (single-domain), 150 (multi-domain)
- **Mixed precision**: `use_bf16: true`

**Smoke Test:**
- **Global batch size**: 8
- **Per-core batch size**: 1
- **Gradient accumulation**: 1 step
- **Max steps**: 10
- **Mixed precision**: `use_bf16: true`

## Commands Reference

### üö® **CRITICAL: Always use `--worker=all`**
TPU distributed training requires coordination across all workers. Use `--worker=all` for training, dependency installation, and git operations.

```bash
# Environment variables for remote execution
export TPU_NAME=oct-jepa2-v4-32
export ZONE=us-central2-b
export PROJECT_ID=d-oct-foundational-model
```

### Training Commands

#### Local Execution (on TPU VM)
```bash
# Single-domain pretraining
bash run_tpu_xla.sh configs/pretrain_vjepa_single_domain.yaml

# Multi-domain pretraining
bash run_tpu_xla.sh configs/pretrain_vjepa_multi_domain.yaml

# Smoke test
bash run_tpu_xla.sh configs/smoke_test.yaml
```

#### Remote Execution (from local machine)
```bash
# Smoke test
gcloud compute tpus tpu-vm ssh ${TPU_NAME} \
    --zone=${ZONE} \
    --project=${PROJECT_ID} \
    --worker=all \
    --command="export PATH=/home/layne/miniconda/envs/torch-xla/bin:\$PATH && cd ~/3d-oct-foundation-model && bash run_tpu_xla.sh configs/smoke_test.yaml"

# Single-domain pretraining
gcloud compute tpus tpu-vm ssh ${TPU_NAME} \
    --zone=${ZONE} \
    --project=${PROJECT_ID} \
    --worker=all \
    --command="export PATH=/home/layne/miniconda/envs/torch-xla/bin:\$PATH && cd ~/3d-oct-foundation-model && bash run_tpu_xla.sh configs/pretrain_vjepa_single_domain.yaml"

# Multi-domain pretraining
gcloud compute tpus tpu-vm ssh ${TPU_NAME} \
    --zone=${ZONE} \
    --project=${PROJECT_ID} \
    --worker=all \
    --command="export PATH=/home/layne/miniconda/envs/torch-xla/bin:\$PATH && cd ~/3d-oct-foundation-model && bash run_tpu_xla.sh configs/pretrain_vjepa_multi_domain.yaml"
```

### Development Workflow

#### üö® **CRITICAL WORKFLOW: Code Changes ‚Üí TPU Deployment**

**EVERY time you make changes to local files, you MUST follow this complete workflow:**

```bash
# 1. Local: Stage, commit, and push changes
git add .
git commit -m "Your commit message"
git push

# 2. TPU: Pull changes to ALL workers (MANDATORY)
gcloud compute tpus tpu-vm ssh ${TPU_NAME} \
    --zone=${ZONE} \
    --project=${PROJECT_ID} \
    --worker=all \
    --command="cd ~/3d-oct-foundation-model && git pull"
```

**‚ö†Ô∏è Why this is CRITICAL:**
- TPU workers operate independently and don't auto-sync
- Code changes only exist locally until git push + TPU git pull
- Running training with stale code leads to confusing results
- ALL 4 workers must have the same code version for distributed training

#### Additional Development Commands
```bash
# Pull code updates to all workers (after local git push)
gcloud compute tpus tpu-vm ssh ${TPU_NAME} \
    --zone=${ZONE} \
    --project=${PROJECT_ID} \
    --worker=all \
    --command="cd ~/3d-oct-foundation-model && git pull"

# Install dependencies on all workers (MUST use worker=all)
gcloud compute tpus tpu-vm ssh ${TPU_NAME} \
    --zone=${ZONE} \
    --project=${PROJECT_ID} \
    --worker=all \
    --command="export PATH=/home/layne/miniconda/envs/torch-xla/bin:\$PATH && cd ~/3d-oct-foundation-model && pip install -r requirements.txt"

# Check TPU status
gcloud compute tpus tpu-vm ssh ${TPU_NAME} \
    --zone=${ZONE} \
    --project=${PROJECT_ID} \
    --worker=all \
    --command="export PATH=/home/layne/miniconda/envs/torch-xla/bin:\$PATH && python -c 'import torch_xla.runtime as xr; print(\"TPU cores:\", xr.local_device_count())'"
```

## Technical Implementation Details

### Data Pipeline
- **GCS DICOM Reader**: Streaming with enhanced pixel data validation
- **Manifest Parser**: TSV parsing with device detection and participant filtering
- **Transforms**: MONAI 3D pipeline with memory-efficient processing
- **Error Handling**: Graceful handling of corrupted/missing DICOM files

### V-JEPA2 Architecture
- **Context Encoder**: 3D ViT backbone with learnable position embeddings
- **Target Encoder**: EMA-updated encoder with momentum scheduling (0.996 ‚Üí 1.0)
- **Predictor**: 2-layer MLP with BatchNorm + GELU activation
- **Loss Function**: Normalized MSE loss on masked patches

### XLA/TPU Training
- **Distributed**: 16 TPU cores with XLA multiprocessing
- **Mixed Precision**: BF16 support via config (`use_bf16: true`)
- **Memory Management**: Gradient accumulation + automatic OOM recovery
- **Checkpointing**: GCS-based saving with W&B artifact integration
- **Multiprocessing**: `forkserver` start method for Python 3.11 + XLA 2.7.0 compatibility

## PyTorch 2.7.1 / XLA 2.7.0 Compatibility

### Key Changes
- **API Updates**: Use `torch_xla.runtime.world_size()` instead of deprecated `xm.xrt_world_size()`
- **Launcher**: Use `xmp.spawn(_mp_fn, nprocs=None)` - let XLA auto-detect devices
- **Environment**: Set `PJRT_DEVICE=TPU` for device coordination
- **Multiprocessing**: Use `forkserver` start method for compatibility

### Verified Working Configuration
- ‚úÖ **16 TPU workers** spawned successfully across 4 nodes
- ‚úÖ **V-JEPA3D model** (29.4M parameters) running on all workers
- ‚úÖ **W&B monitoring** with concurrent runs
- ‚úÖ **Data pipeline** with robust DICOM validation
- ‚úÖ **No crashes** from empty batches or corrupted files

## Recent Improvements (August 2025)

### DICOM Validation Enhancement
- **Enhanced validation**: Check for PixelData tag `(7FE0,0010)` before accessing pixel_array
- **Graceful error handling**: Skip corrupted files instead of crashing
- **Empty batch handling**: Return `None` from collate function instead of raising `RuntimeError`

### Warning Fixes
- **Gradient accumulation**: Fixed batch size consistency warnings
- **BF16 modernization**: Added `use_bf16` config option to replace deprecated `XLA_USE_BF16`
- **Training pipeline**: Now runs warning-free while maintaining functionality

### Current Status

**Pretraining Pipeline:**
```
‚úÖ XLA distributed training: 16 TPU workers operational
‚úÖ W&B monitoring: Multiple concurrent runs completed
‚úÖ Data pipeline: 601 DICOM files processed successfully
‚úÖ Error handling: Robust validation prevents crashes
‚úÖ Mixed precision: Modern BF16 configuration working
‚úÖ Warning-free: All configuration issues resolved
‚úÖ Model checkpoints: 3 trained foundation models saved locally
```

**Fine-Tuning Pipeline (Implementation Complete):**
```
‚úÖ Fine-tuning framework: Complete implementation aligned with V-JEPA2 architecture
‚úÖ B2 data integration: Full storage pipeline with S3-compatible interface
‚úÖ Classification pipeline: Linear probe + MLP head modes implemented
‚úÖ Multi-checkpoint comparison: Ready for evaluation of all 3 pretrained models
‚úÖ Core modules: Data loading, transforms, models, and training infrastructure
```

## Troubleshooting

### Common Issues
- **TPU Permission Errors**: Usually resolve automatically after retry
- **Empty Batches**: Now handled gracefully - training continues with next batch
- **DICOM Corruption**: Files without pixel data are automatically skipped
- **Memory Issues**: Automatic OOM recovery with batch size reduction

### OOM Handling Strategy
1. Halve `per_core_batch_size`
2. If <1, set to 1 and increase `grad_accum_steps`  
3. If still OOM, reduce `image_size` to [64, 320, 320]

---

## Fine-Tuning Setup

### Available Checkpoints
Three V-JEPA2 foundation models trained and ready:
1. **Multi-domain**: Trained on all device types (heidelberg, topcon, zeiss)
2. **Single-domain 01**: Trained on specific device subset  
3. **Single-domain 02**: Trained on specific device subset

### Fine-Tuning Task
- **Objective**: 4-class diabetes status classification
- **Classes**: healthy, pre_diabetes_lifestyle_controlled, oral_medication_controlled, insulin_dependent
- **Data**: Backblaze B2 storage with train/val/test splits
- **Approach**: Compare all 3 checkpoints via linear probe + full fine-tuning

### Implementation Status
‚úÖ **Complete Fine-Tuning Framework**:
1. **Data Pipeline**: B2 storage, DICOM/NIfTI/NPY readers, V-JEPA2 transforms, caching
2. **Model Components**: Encoder loader, classification heads, combined models  
3. **Infrastructure**: Dataset, DataLoader, multi-checkpoint support, ensemble models
4. **Configuration**: Environment setup, dependency management, connection testing

### ‚úÖ **PIPELINE VALIDATION COMPLETE - READY FOR PHASE 2 TRAINING**

**All Priority 0 (P0) components implemented and validated:**
1. ‚úÖ **Training Infrastructure**: Complete training loop with metrics, early stopping, W&B integration
2. ‚úÖ **Validation Suite**: Comprehensive smoke tests and pipeline validation PASSED
3. ‚úÖ **Configuration Management**: Hydra configs for linear probe, fine-tuning, and sweeps
4. ‚úÖ **Entry Points**: Training runner with both programmatic and CLI interfaces
5. ‚úÖ **Environment Setup**: Conda environment `oct_finetuning` with all dependencies
6. ‚úÖ **B2 Integration**: Connection validated, OCT data locator working, labels loading from B2
7. ‚úÖ **PyTorch Compatibility**: Fixed checkpoint loading for PyTorch 2.8+ with `weights_only=False`

### ‚úÖ **SMOKE TESTS PASSED - August 24, 2025**
- **B2 Connection**: ‚úÖ Successfully connected to `eye-dataset` bucket
- **Labels Processing**: ‚úÖ 1067 participants loaded from `ai-readi/dataset/participants.tsv` 
- **Data Splits**: ‚úÖ Train: 743, Val: 159, Test: 159 participants
- **Class Distribution**: ‚úÖ 4-class diabetes classification ready (healthy: 369, pre-diabetes: 242, oral-medication: 321, insulin-dependent: 129)
- **OCT Data Locator**: ‚úÖ DICOM files mapped from `ai-readi/dataset/retinal_oct/structural_oct/`
- **V-JEPA2 Encoders**: ‚úÖ All 3 checkpoints (multi-domain, single-domain-01/02) load successfully
- **Model Pipeline**: ‚úÖ Forward passes validated, 29.4M parameter encoders ‚Üí 768-dim embeddings
- **Training Framework**: ‚úÖ Debug training initiated successfully with B2 data integration

### **Current Phase: P2 - TPU Migration (READY TO DEPLOY)**
**Status**: üöÄ **PIPELINE VALIDATED - READY FOR TPU DEPLOYMENT**
**Local Validation Complete**:
1. ‚úÖ **Pipeline Validated**: Complete fine-tuning framework working on CPU (4+ hours runtime)
2. ‚úÖ **All Issues Fixed**: Memory safety, API errors, transforms all resolved
3. ‚úÖ **Data Integration**: B2 storage, OCT locator, model loading all functional
4. üöÄ **TPU Migration**: Deploy to TPU for 10-100x faster training

**Rationale for TPU Migration**:
- **CPU Limitations**: Extremely slow (4+ hours, still early epochs), batch size 1, constant memory issues
- **TPU Advantages**: 16 cores, large memory, proven infrastructure, hours vs days training time
- **Validation Complete**: Local testing proved all components work correctly

### Fine-Tuning Directory Structure
```
finetuning/
‚îú‚îÄ‚îÄ storage/b2.py          # ‚úÖ B2 storage utilities
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ labels.py          # ‚úÖ TSV processing, class mapping, splits
‚îÇ   ‚îú‚îÄ‚îÄ locator.py         # ‚úÖ Participant ID ‚Üí B2 key resolution
‚îÇ   ‚îú‚îÄ‚îÄ io.py              # ‚úÖ Multi-format volume readers (DICOM/NIfTI/NPY)
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py         # ‚úÖ OCT dataset with error handling
‚îÇ   ‚îî‚îÄ‚îÄ transforms.py      # ‚úÖ V-JEPA2 compatible preprocessing
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ encoder_loader.py  # ‚úÖ V-JEPA2 checkpoint loading
‚îÇ   ‚îú‚îÄ‚îÄ classifier.py      # ‚úÖ Linear probe + MLP heads
‚îÇ   ‚îî‚îÄ‚îÄ model.py           # ‚úÖ Combined model with pooling
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ loop.py            # ‚úÖ Training loop with metrics & early stopping
‚îÇ   ‚îî‚îÄ‚îÄ run.py             # ‚úÖ Hydra-compatible training runner
‚îú‚îÄ‚îÄ utils/checks.py        # ‚úÖ Comprehensive validation & smoke tests
‚îî‚îÄ‚îÄ experiments/sweep.py   # üìã Multi-checkpoint evaluation (planned)
```

---

### Configuration Files
```
configs/
‚îú‚îÄ‚îÄ cls_linear_probe.yaml  # ‚úÖ Linear probe baseline
‚îú‚îÄ‚îÄ cls_finetune.yaml      # ‚úÖ Full fine-tuning mode  
‚îú‚îÄ‚îÄ sweep_checkpoints.yaml # ‚úÖ Multi-checkpoint comparison
‚îî‚îÄ‚îÄ debug.yaml             # ‚úÖ Debug/smoke testing mode
```

### Smoke Test Suite
- **Entry Point**: `./run_smoke_tests.py` (executable)
- **Validates**: B2 connection, labels processing, OCT locator, dataset creation, encoder loading, model forward passes
- **Safe Testing**: Uses dummy data when B2 credentials unavailable
- **Comprehensive**: Tests all pipeline components end-to-end
- **Status**: ‚úÖ B2 connection working, üîß final fixes in progress

### Environment Setup Commands
```bash
# Activate conda environment
source /opt/anaconda3/bin/activate && conda activate oct_finetuning

# Set B2 credentials
export AWS_ACCESS_KEY_ID="<your-b2-access-key-id>"
export AWS_SECRET_ACCESS_KEY="<your-b2-secret-access-key>"  
export AWS_DEFAULT_REGION="us-west-004"
export S3_ENDPOINT_URL="https://s3.us-west-004.backblazeb2.com"
export PYTHONPATH=/Users/layne/Mac/Acdamic/UCInspire/3d_oct_fundation_model:$PYTHONPATH

# Smoke tests (PASSED)
python run_smoke_tests.py --test-b2 --quick

# P2 TPU Migration Commands (Current Priority)
# 1. Upload all fixes and fine-tuning code to TPU
git add . && git commit -m "Complete fine-tuning pipeline with all fixes" && git push
gcloud compute tpus tpu-vm ssh oct-jepa2-v4-32 --zone=us-central2-b --project=d-oct-foundational-model --worker=all --command="cd ~/3d-oct-foundation-model && git pull"

# 2. Run P1 linear probe evaluation on TPU (much faster)
gcloud compute tpus tpu-vm ssh oct-jepa2-v4-32 --zone=us-central2-b --project=d-oct-foundational-model --worker=all --command="export PATH=/home/layne/miniconda/envs/torch-xla/bin:\$PATH && cd ~/3d-oct-foundation-model && python -m finetuning.train.run --config-name cls_linear_probe"

# 3. Multi-checkpoint comparison (TPU)
gcloud compute tpus tpu-vm ssh oct-jepa2-v4-32 --zone=us-central2-b --project=d-oct-foundational-model --worker=all --command="export PATH=/home/layne/miniconda/envs/torch-xla/bin:\$PATH && cd ~/3d-oct-foundation-model && python -m finetuning.train.run --config-name sweep_checkpoints -m"
```

---

### Key Fixes Applied
1. **PyTorch 2.8 Compatibility**: Added `weights_only=False` to checkpoint loading for trusted V-JEPA2 checkpoints
2. **B2 Data Paths**: Updated from `fine-tuneing-data/` to `ai-readi/dataset/retinal_oct/` (actual bucket structure)
3. **Labels Location**: Updated to `ai-readi/dataset/participants.tsv` on B2
4. **Environment Dependencies**: All required packages installed in `oct_finetuning` conda environment

### Discovered B2 Structure
```
eye-dataset/
‚îî‚îÄ‚îÄ ai-readi/
    ‚îî‚îÄ‚îÄ dataset/
        ‚îú‚îÄ‚îÄ participants.tsv          # Labels file
        ‚îú‚îÄ‚îÄ retinal_oct/             # OCT volumes
        ‚îú‚îÄ‚îÄ retinal_octa/            # OCTA data
        ‚îú‚îÄ‚îÄ retinal_photography/     # Fundus photos
        ‚îî‚îÄ‚îÄ clinical_data/           # Clinical metadata
```

---

*Last updated: August 24, 2025 - P0 validation complete, entering P1 multi-checkpoint evaluation phase*