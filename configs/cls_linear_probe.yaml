project_name: oct_cls_v1
seed: 42

paths:
  labels_tsv: "/Users/layne/Mac/Acdamic/UCInspire/3d_oct_fundation_model/fine-tuneing-data/participants.tsv"
  # Set one of these per run; or use Hydra multirun with a list
  checkpoint_path: "/Users/layne/Mac/Acdamic/UCInspire/checkpoints/best_checkpoint_multi_domain.pt"
  s3_bucket: "eye-dataset"
  s3_prefix: ""         # TODO: confirm exact B2 bucket structure for fine-tuning data

s3:
  endpoint_env: "S3_ENDPOINT_URL"

data:
  num_workers: 4
  cache_dir: "/tmp/oct_cache"
  batch_size: 2
  val_batch_size: 2
  augment:
    flip: true
    intensity_jitter: true
    resize: [64, 384, 384]         # D,H,W â€” match V-JEPA2 pretraining

classes:
  mapping:
    healthy: 0
    pre_diabetes_lifestyle_controlled: 1
    oral_medication_and_or_non_insulin_injectable_medication_controlled: 2
    insulin_dependent: 3

model:
  emb_dim: 768
  freeze_encoder: true
  unfreeze_at_epoch: -1
  pool_method: "mean"
  head:
    hidden: 0
    dropout: 0.1

train:
  epochs: 50
  lr_head: 1.0e-3
  lr_encoder: 3.0e-5
  weight_decay: 1.0e-4
  optimizer: "AdamW"
  scheduler: "cosine"
  warmup_epochs: 2
  class_weights: "auto"
  precision: "fp32"
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.001

log:
  wandb: false
  wandb_project: "3d-oct-foundation-model"
  wandb_entity: "laynzzz-university-at-buffalo"
  ckpt_dir: "./runs/cls_lp_v1"
  save_best: true
  save_last: true