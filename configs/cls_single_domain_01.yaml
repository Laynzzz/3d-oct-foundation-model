project_name: oct_cls_single_domain_01
seed: 42

paths:
  labels_tsv: "ai-readi/dataset/participants.tsv"  # B2 path to participants file
  checkpoint_path: "gs://layne-tpu-code-sync/checkpoints/vjepa2/vjepa2_single_domain_01/best_checkpoint.pt"
  s3_bucket: "eye-dataset"
  s3_prefix: "ai-readi/dataset/retinal_oct/"  # B2 prefix for OCT data

s3:
  endpoint_env: "S3_ENDPOINT_URL"

data:
  num_workers: 2              # Increased for better throughput
  cache_dir: "/tmp/oct_cache"
  batch_size: 1               # Keep at 1 for now - DistributedSampler provides speedup
  val_batch_size: 1
  use_distributed: true       # Enable DistributedSampler for TPU
  persistent_workers: true    # Keep workers warm
  prefetch_factor: 2          # Pre-load batches
  augment:
    flip: true
    intensity_jitter: true
    resize: [64, 384, 384]         # D,H,W — match V-JEPA2 pretraining

classes:
  mapping:
    healthy: 0
    pre_diabetes_lifestyle_controlled: 1
    oral_medication_and_or_non_insulin_injectable_medication_controlled: 2
    insulin_dependent: 3

model:
  emb_dim: 768
  freeze_encoder: true        # ✅ ENCODER FROZEN
  unfreeze_at_epoch: -1       # ✅ NEVER UNFREEZE (-1 means never)
  pool_method: "mean"
  head:
    hidden: 0                 # Linear probe (no hidden layers)
    dropout: 0.1

train:
  epochs: 50
  lr_head: 1.0e-3            # Only head will be trained
  lr_encoder: 3.0e-5         # Not used since encoder frozen
  weight_decay: 1.0e-4
  optimizer: "AdamW"
  scheduler: "cosine"
  warmup_epochs: 2
  class_weights: "auto"
  precision: "fp32"
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.001

log:
  wandb: true
  wandb_project: "3d-oct-foundation-model"
  wandb_entity: "laynzzz-university-at-buffalo"
  ckpt_dir: "./runs/cls_single_domain_01"
  save_best: true
  save_last: true